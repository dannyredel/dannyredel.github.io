{
  "hash": "dd15c66c7bad5e90ab39c3e84ddedf8f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal ARIMA Approach to Estimate Price Policy Changes on Sales\"\nauthor: Daniel Redel\ndate: \"2024-05-22\"\ncategories: [Causal Inference, R, Time Series, ARIMA]\nimage: \"carima_cover.png\"\nformat: \n  html:\n    toc: true\n    code-fold: false\n    html-math-method: katex\n    number-sections: true\n    colorlinks: true\n    link-citations: true\nbibliography: references.bib\n---\n\nC-ARIMA to estimate the causal effects in time series settings where no control unit is available.\n\n\n\n**What is the effect of price reduction on sales?** Imagine you are a popular e-commerce platform for books, such as [Waterstones](https://www.waterstones.com/). As a part of your marketing strategy, you decide to reduce prices on all books. Now, you're eager to assess the impact of this decision on the daily volume of sales. How can you measure this effect?\n\nObservational studies such as this pose significant challenges to identifying and estimating **causal effects**. Unlike [**A/B testing**](https://dannyredel.github.io/posts/ab_testing1/1_ab_testing.html) or randomized experiments, where the assignment mechanism (the process determining which units receive treatment and which receive control) is controlled and known, observational studies lack this clarity.\n\nPopular methods such as [Difference-in-Differences (DiD)](https://en.wikipedia.org/wiki/Difference_in_differences) [@angrist2008] and [Synthetic Control Methods (SCM)](https://en.wikipedia.org/wiki/Synthetic_control_method) [@abadie2010] have been extensively used to evaluate the impact of interventions in the absence of experimental data across various fields, including economics and marketing. Recent advancements even combine these approaches, as seen in the [Synthetic Difference-in-Differences (SDiD)](https://matheusfacure.github.io/python-causality-handbook/25-Synthetic-Diff-in-Diff.html) [@arkhangelsky2019] estimator.\n\nHowever, **these methods require the presence of control units** that did not experience the intervention. In cases of widespread policy changes affecting *all units*—such as our book price reduction example—finding untreated units is often impossible.\n\nOn a recent article published in *The Econometrics Journal* ([Volume 26, Issue 1](https://academic.oup.com/ectj/issue/26/1)), @menchetti2022 propose a novel approach, **Causal-ARIMA (C-ARIMA)**, to estimate the causal effect of an intervention in observational time series settings where no control unit is available.\n\nIn this post, we will explore how to use `C-ARIMA` in `R` estimate the impact of a treatment in settings where no controls or comparisons are available. We will demonstrate that, under certain structural assumptions, the Causal ARIMA approach can effectively recover the average treatment effect, providing insights for decision-making in scenarios where traditional methods may not suffice.\n\n# Online Book Sales: Simulated Data\n\nWe illustrate how the approach can be applied by estimating the causal effect of a **permanent price reduction on daily online book sales**. I generated a simulated dataset in which we observe a time series of daily sales overtime (`y`) and additional characteristics summarized in our variable `x1`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate data\nn <- 100\nset.seed(1)\nx1 <- 100 + arima.sim(model = list(ar = 0.999), n = n)\ny <- 1.2 * x1 + rnorm(n)\ny[floor(n * 0.71):n] <- y[floor(n * 0.71):n] + 10\ndata <- data.frame(y, x1)  # Instead of cbind\ndates <- seq.Date(from = as.Date(\"2014-01-05\"), by = \"days\", length.out = n)\nstart <- as.numeric(strftime(as.Date(dates[1], \"%Y-%m-%d\"), \"%u\"))\n\n# Adding a fictional intervention\nint.date <- as.Date(\"2014-03-16\")\n\n# Combine data and dates into a dataframe\ndf <- data.frame(Date = dates, data, stringsAsFactors = FALSE)\n\n# Add day of the week as a column\ndf$DayOfWeek <- weekdays(df$Date)\n```\n:::\n\n\nWe turn this into a `tsibble` object using the `tsibble()` function from the `fable` package [@hyndman2018]. This allows us to integrate closely with the `tidyverse` collection of packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1 <- df  %>% \n  as_tsibble(index = Date)\n```\n:::\n\n\n@tbl-1 shows a glimpse of the dataset:\n\n\n::: {#tbl-1 .cell tbl.align='center' tbl-cap='Simulated Sales Dataset Overview'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Date </th>\n   <th style=\"text-align:left;\"> y </th>\n   <th style=\"text-align:left;\"> x1 </th>\n   <th style=\"text-align:left;\"> DayOfWeek </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2014-01-05 </td>\n   <td style=\"text-align:left;\"> 105.2950 </td>\n   <td style=\"text-align:left;\"> 88.21513 </td>\n   <td style=\"text-align:left;\"> Sunday </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2014-01-06 </td>\n   <td style=\"text-align:left;\"> 105.8943 </td>\n   <td style=\"text-align:left;\"> 88.48415 </td>\n   <td style=\"text-align:left;\"> Monday </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2014-01-07 </td>\n   <td style=\"text-align:left;\"> 106.6209 </td>\n   <td style=\"text-align:left;\"> 87.87684 </td>\n   <td style=\"text-align:left;\"> Tuesday </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2014-01-08 </td>\n   <td style=\"text-align:left;\"> 106.1572 </td>\n   <td style=\"text-align:left;\"> 86.77954 </td>\n   <td style=\"text-align:left;\"> Wednesday </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n@fig-sales shows the time series of volume of sales. with the intervention date starting on *March 15, 2014*:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Volume of Sales ($) Evolution](carima_data_files/figure-html/fig-sales-1.png){#fig-sales fig-align='center' width=672}\n:::\n:::\n\n\nIn this example, appropriate control series could be the sales of products that are not impacted by the *'price reduction'* policy. However, if ***all products were impacted*** by the intervention, finding a valid comparison group becomes challenging.\n\nLet's also assume all products received the intervention ***simultaneously***, thereby precluding the adoption of the DiD estimators developed under variation in timing. Therefore, in our setting none of the methods mentioned above is applicable.\n\n# Causal ARIMA Time Series\n\n::: {.callout-warning appearance=\"minimal\"}\n*The main idea behind the C-ARIMA methods consists of exploiting the time dynamics in the pre-intervention period to predict the series in the absence of intervention.*\n:::\n\n**Autoregressive Integrated Moving Average** (**ARIMA**) models are classic statistical approaches to time series forecasting, when we are usually interested in **predicting future scenarios**. ARIMA models have desirable properties (tractability, consistency of the estimator of model parameters), and are suited to describe a wide variety of time series generated by complex, non-stationary processes.\n\nIn Contrast, **C-ARIMA** is used to estimate the **causal effect** of an intervention in observational time series settings under a potential outcomes approach. Therefore, it complements the set of tools for causal inference on **observational time series data**.\n\n::: {.callout-caution appearance=\"minimal\"}\n**C-ARIMA** is tailored to estimate the effect of an intervention **when no control series is available** and when the number of **pre-treatment periods is large**, since it allows to fully exploit useful information provided by the pre-intervention dynamics. Conversely, by focusing on a few time points, DiD estimators and SCM have a limited ability to exploit long pre-treatment periods.\n:::\n\nOftentimes researchers are interested in a **cumulative sum of point effects**, e.g., Papadogeorgou et al. (2018) focus on estimating the total number of hospital readmissions due to the Hospital Readmission Reduction Program over the entire post-intervention period. Therefore, we also provide test statistics for two additional effects: the **cumulative** and the **temporal average effect**.\n\n## Estimation Procedure and Inference\n\nIn order to estimate the causal effects with C-ARIMA, we need to follow a three-step process:\n\n1.  Estimate the ARIMA model only in the **pre-intervention period**, so as to learn the dynamics of the dependent variable and the links with the covariates without being influenced by the treatment;\n2.  Based on the process learned in the pre-intervention period, **perform a prediction step** and obtain an estimate of the counterfactual outcome during the post-intervention period in the absence of intervention;\n3.  By comparing the *observations* with the corresponding *forecasts* at any time point in the post-intervention period, **evaluate the resulting differences**, which represent the **estimated point causal effects**.\n\nLet $W_{i,t} ∈ (0, 1)$ be a random variable describing the **treatment assignment** of unit $i ∈ {1, . . . , N}$ at time $t ∈ {1, . . . , T}$, where $1$ denotes that a “treatment” (or “intervention”) has taken place and $0$ denotes control. Then, our **estimands of interest** are:\n\n$$\n\\text{Point Causal Effect: } \\tau_t(w,w') = Y_t(w) - Y_t(w') \\\\\n\\text{Cumulative Causal Effect: } \\Delta_t(w,w') = \\sum^{t}_{s+t^*+1} \\tau_t(w,w') \\\\\n\\text{Average Causal Effect: } \\bar\\tau_t(w,w') = \\frac{\\Delta_t(w,w')}{t-t^*}\n$$\n\nThen, we have two options to perform inference on the estimated effects: (i) we can rely in the **Normality** of the error terms, or (ii) we can resort to a **Bootstrap Strategy** by using resampled residuals in order to compute empirical critical values.\n\n# Application\n\n## C-ARIMA using `fable` package\n\nLet's start by fitting an ARIMA model on our pre-intervention period (between January and March 15):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- df1 |>\n    filter_index(\"2014-01-05\" ~ \"2014-03-15\") |>\n    model(ARIMA(y ~ x1)\n)\n\nreport(fit) ## ARIMA(0,0,0)(0,0,1)[7]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: y \nModel: LM w/ ARIMA(0,0,0)(0,0,1)[7] errors \n\nCoefficients:\n        sma1      x1\n      0.2050  1.1993\ns.e.  0.1229  0.0019\n\nsigma^2 estimated as 1.429:  log likelihood=-110.95\nAIC=227.9   AICc=228.26   BIC=234.64\n```\n\n\n:::\n:::\n\n\nNow we estimate the counterfactual outcome during the post-intervention period in the absence of intervention. For this, we first need to include the post-intervention evolution of the `x1` regressor:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf1_x1 <- df1 %>% \n  select(Date, x1) %>% \n  filter_index(\"2014-03-16\" ~ \"2014-04-14\")\n```\n:::\n\n\nNow we generate the forecasted values:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the forecasted values using the fitted model\nforecast_result <- forecast(fit, new_data = df1_x1)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Sales ($) ARIMA Forecast](carima_data_files/figure-html/fig-carima1-1.png){#fig-carima1 fig-align='center' width=672}\n:::\n:::\n\n\n@fig-carima1 provides a graphical representation of the observed time series and the forecasted series in the absence of intervention. At the 1-month time horizon, the causal effect is significantly positive at the 5% level. Additionally, our ARIMA model is able to closely follow the series during the pre-intervention period. We can summarize this fitness level by calculating RMSE and R-Squared scores:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##RMSE & R2_Score\nfore1 <- fitted(fit) %>% select(Date, .fitted)\n\naccuracy1 <- df1 %>% \n  left_join(fore1, by=\"Date\") %>% \n  filter_index(\"2014-01-05\" ~ \"2014-03-15\")\n\nRMSE_CARIMA <- RMSE(accuracy1$.fitted, accuracy1$y)\nR2_CARIMA <- R2_Score(accuracy1$.fitted, accuracy1$y)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nPre-Intervention RMSE: 1.178076 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPre-Intervention R-Squared: 0.8794006 \n```\n\n\n:::\n:::\n\n\n### Point Causal Effects\n\nThe point causal effect at time $t$ can be estimated with the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nATE_df <- df1 %>% \n  filter(Date >= ymd(\"2014-03-16\") & Date <= ymd(\"2014-04-14\"))\n\n# Point Effect\npoint_effect <- ATE_df$y - forecast_result$y\n\n# Calculate the point estimate\npoint_estimate <- mean(point_effect)\n\n# Calculate the lower bound of the 95% confidence interval\nlower_bound <- quantile(point_effect, 0.025)\n\n# Calculate the upper bound of the 95% confidence interval\nupper_bound <- quantile(point_effect, 0.975)\n\n# Create a data frame\ncausal_effect_df <- data.frame(\n  Date = ATE_df$Date,\n  Point_Estimate = point_estimate,\n  Lower_Bound = lower_bound,\n  Upper_Bound = upper_bound\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Causal Effect with 95% Confidence Intervals](carima_data_files/figure-html/fig-point_effect1-1.png){#fig-point_effect1 fig-align='center' width=672}\n:::\n:::\n\n\nIn @fig-point_effect1 we observe that the impact of the price policy change is quite constant in time, around \\$10.\n\n### Average Causal Effects\n\nThe temporal average effect indicates the number of additional books sold daily, on average, due to the permanent price reduction. We also want to do some inference, standard errors and confidence intervals. A confidence interval gives an interval within which we expect $y_t$ to lie with a specified probability. For example, assuming that distribution of observations is normal, a 95% prediction interval for the $h$- step forecast is:\n\n$$\n\\hat{y}_{T+h|T} ± (1.96) \\hat \\sigma_h\n$$\n\nLet's code this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the point estimate\naverage_treatment_effect  <- mean(point_estimate)\n\n# Standard error of the point estimates\nvariance_point_effect <- distributional::variance(point_effect)\nstandard_deviation <- sqrt(variance_point_effect)\nstandard_error <- standard_deviation / sqrt(length(point_effect))\n\n# Confidence interval for the average treatment effect\nci_lower <- average_treatment_effect - 1.96 * mean(standard_error)\nci_upper <- average_treatment_effect + 1.96 * mean(standard_error)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nAverage Causal Effect: 10.39115 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error: 0.2217059 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% Confidence Interval: [ 9.956609 ,  10.8257 ]\n```\n\n\n:::\n:::\n\n\n### Bootstrapped Confidence Intervals\n\nWhen a normal distribution for the residuals is an unreasonable assumption, one alternative is to use **bootstrapping**, which only assumes that the residuals are uncorrelated with constant variance. This is easily achieved by simply adding `bootstrap=TRUE` in the `forecast()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforecast_result <- forecast(fit, new_data = df1_x1, bootstrap=TRUE)\n\n# Point Effect\npoint_effect <- ATE_df$y - forecast_result$y\n\n# Calculate the point estimate\npoint_estimate <- mean(point_effect)\n\n# Calculate the point estimate\naverage_treatment_effect  <- mean(point_estimate)\n\n# Standard error of the point estimates\nvariance_point_effect <- distributional::variance(point_effect)\nstandard_deviation <- sqrt(variance_point_effect)\nstandard_error <- standard_deviation / sqrt(length(point_effect))\n\n\n# Confidence interval for the average treatment effect\nci_lower <- average_treatment_effect - 1.96 * mean(standard_error)\nci_upper <- average_treatment_effect + 1.96 * mean(standard_error)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nAverage Treatment Effect: 10.38964 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error: 0.2178212 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% Confidence Interval: [ 9.962708 ,  10.81657 ]\n```\n\n\n:::\n:::\n\n\nThe results are quite similar in this case.\n\n## The `CausalARIMA` Package\n\nThe authors of the paper are developing an `R` package called `CausalArima` for easier and faster application of the proposed method. The development version of the package can be accessed from <https://github.com/FMenchetti/CausalArima>.\n\nLet's see how it works:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Install the missing dependencies first\n# install.packages(c(\"tidybayes\", \"forecast\", \"ggplot2\", \"gridExtra\", \"quantmod\"))\n\n# First update the locked packages (now that nothing holds them)\n# install.packages(c(\"xfun\", \"stringi\", \"jsonlite\", \"rlang\", \"cli\", \n#                    \"digest\", \"glue\", \"Rcpp\", \"vctrs\", \"stringr\", \"ggplot2\"))\n\n# Then install CausalArima\n#devtools::install_github(\"FMenchetti/CausalArima\")\n\nlibrary(CausalArima)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Causal effect estimation\n# fit the model - Causal effect estimation\nce <- CausalArima(y = ts(y, start = start, frequency = 1), \n                  dates = dates, \n                  int.date = int.date,\n                  xreg =x1, \n                  nboot = 1000)\n```\n:::\n\n\nHow to obtain the plot of the forecast:\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Sales ($) ARIMA Forecast](carima_data_files/figure-html/fig-carima2-1.png){#fig-carima2 fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimpact_p <- plot(ce, type=\"impact\", color_line=mycolors[1], color_intervals=\"#91D1C2B2\")\ngrid.arrange(impact_p$plot, impact_p$cumulative_plot)\n```\n\n::: {.cell-output-display}\n![](carima_data_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n### Inference\n\nDoing inference with this package is straightforward, with the options of using the normality assumption or the bootstrap alternative:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ce)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                      \nPoint causal effect            12.257 \nStandard error                 1.211  \nLeft-sided p-value             1      \nBidirectional p-value          0      \nRight-sided p-value            0      \n                                      \nCumulative causal effect       310.709\nStandard error                 6.634  \nLeft-sided p-value             1      \nBidirectional p-value          0      \nRight-sided p-value            0      \n                                      \nTemporal average causal effect 10.357 \nStandard error                 0.221  \nLeft-sided p-value             1      \nBidirectional p-value          0      \nRight-sided p-value            0      \n```\n\n\n:::\n\n```{.r .cell-code}\nsummary_model <- impact(ce, format=\"html\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_model$impact_norm$average\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> sd </th>\n   <th style=\"text-align:right;\"> p_value_left </th>\n   <th style=\"text-align:right;\"> p_value_bidirectional </th>\n   <th style=\"text-align:right;\"> p_value_right </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 10.357 </td>\n   <td style=\"text-align:right;\"> 0.221 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n   <td style=\"text-align:right;\"> 0 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary_model$impact_boot$average\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> estimates </th>\n   <th style=\"text-align:right;\"> inf </th>\n   <th style=\"text-align:right;\"> sup </th>\n   <th style=\"text-align:right;\"> sd </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> observed </td>\n   <td style=\"text-align:right;\"> 117.049 </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n   <td style=\"text-align:right;\"> NA </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> forecasted </td>\n   <td style=\"text-align:right;\"> 106.692 </td>\n   <td style=\"text-align:right;\"> 106.264 </td>\n   <td style=\"text-align:right;\"> 107.142 </td>\n   <td style=\"text-align:right;\"> 0.222 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> absolute_effect </td>\n   <td style=\"text-align:right;\"> 10.357 </td>\n   <td style=\"text-align:right;\"> 9.907 </td>\n   <td style=\"text-align:right;\"> 10.784 </td>\n   <td style=\"text-align:right;\"> 0.222 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> relative_effect </td>\n   <td style=\"text-align:right;\"> 0.097 </td>\n   <td style=\"text-align:right;\"> 0.093 </td>\n   <td style=\"text-align:right;\"> 0.101 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n# Causal `Prophet`\n\nSo far, we have learned how to apply this framework using ARIMA models to identify causal effects.\n\nHowever, this approach can be **generalized beyond ARIMA models** to include other methods such as Neural Networks, Random Forest, and Exponential Smoothing.\n\nA recent proposal is the **Prophet model**, available via the `fable.prophet` package. This model was introduced by Facebook [@taylor2018], originally designed for forecasting daily data with weekly and yearly seasonality, including holiday effects. It has since been extended to accommodate various types of seasonal data. The Prophet model works best with time series that exhibit strong seasonality and have multiple seasons of historical data.\n\nWe can use the same estimation procedure explained in the previous section, but replacing `ARIMA()` with the `prophet()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"fable.prophet\")\nlibrary(fable.prophet)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- df1 |>\n    filter_index(\"2014-01-05\" ~ \"2014-03-15\") |>\n    model(\n      prophet(y ~ x1 + season(period = 1, order = 2)\n    )\n)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Generate the forecasted values using the fitted model\nforecast_result <- forecast(fit, new_data = df1_x1)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Sales ($) PROPHET Forecast](carima_data_files/figure-html/fig-prohet1-1.png){#fig-prohet1 fig-align='center' width=672}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##RMSE & R2_Score\nfore1 <- fitted(fit) %>% select(Date, .fitted)\n\naccuracy1 <- df1 %>% \n  left_join(fore1, by=\"Date\") %>% \n  filter_index(\"2014-01-05\" ~ \"2014-03-15\")\n\nRMSE_CARIMA <- RMSE(accuracy1$.fitted, accuracy1$y)\nR2_CARIMA <- R2_Score(accuracy1$.fitted, accuracy1$y)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nPre-Intervention RMSE: 1.167918 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPre-Intervention R-Squared: 0.8814713 \n```\n\n\n:::\n:::\n\n\n### Point Causal Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\nATE_df <- df1 %>% \n  filter(Date >= ymd(\"2014-03-16\") & Date <= ymd(\"2014-04-14\"))\n\n# Point Effect\npoint_effect <- ATE_df$y - forecast_result$y\n\n# Calculate the point estimate\npoint_estimate <- mean(point_effect)\n\n# Calculate the lower bound of the 95% confidence interval\nlower_bound <- quantile(point_effect, 0.025)\n\n# Calculate the upper bound of the 95% confidence interval\nupper_bound <- quantile(point_effect, 0.975)\n\n# Create a data frame\ncausal_effect_df <- data.frame(\n  Date = ATE_df$Date,\n  Point_Estimate = point_estimate,\n  Lower_Bound = lower_bound,\n  Upper_Bound = upper_bound\n)\n```\n:::\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Causal Effect with 95% Confidence Intervals](carima_data_files/figure-html/fig-point_effect2-1.png){#fig-point_effect2 fig-align='center' width=672}\n:::\n:::\n\n\n### Average Causal Effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the point estimate\naverage_treatment_effect  <- mean(point_estimate)\n\n# Standard error of the point estimates\nvariance_point_effect <- distributional::variance(point_effect)\nstandard_deviation <- sqrt(variance_point_effect)\nstandard_error <- standard_deviation / sqrt(length(point_effect))\n\n\n# Confidence interval for the average treatment effect\nci_lower <- average_treatment_effect - 1.96 * mean(standard_error)\nci_upper <- average_treatment_effect + 1.96 * mean(standard_error)\n```\n:::\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nAverage Treatment Effect: 11.22149 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Error: 0.2129367 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n95% Confidence Interval: [ 10.80413 ,  11.63884 ]\n```\n\n\n:::\n:::\n\n\nIn the end, we found a slightly higher average causal effect compared to C-ARIMA, but really similar in terms of economic significance.\n\n# Conclusion\n\nIn this article, we demonstrated how to estimate the causal effect of interventions using the **Causal-ARIMA approach**, a useful methods for when control groups are not available. We applied this method to a simulated dataset, showing the impact of a permanent price reduction on daily online book sales.\n\nAdditionally, we explored the potential for generalizing this framework to other time series models, including the **Prophet** model. These tools provide novel solutions for causal inference in observational studies, with many potential applications.\n\n# References {.unnumbered}\n\n::: {#refs}\n:::\n",
    "supporting": [
      "carima_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}